{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1) Install & Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv (Python 3.12.5)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "%pip install yfinance pandas statsmodels numpy matplotlib scikit-learn tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "### 2) Handle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "gs = yf.download(\"GS\", start=\"2011-01-01\", end=\"2021-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "dataset_ex_df = gs.copy()\n",
    "dataset_ex_df = dataset_ex_df.reset_index()\n",
    "dataset_ex_df['Date'] = pd.to_datetime(dataset_ex_df['Date'])\n",
    "dataset_ex_df.set_index('Date', inplace=True)\n",
    "dataset_ex_df = dataset_ex_df['Close'].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 3) Define & Display ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ARIMA model\n",
    "def arima_forecast(history):\n",
    "    # Fit the model\n",
    "    model = ARIMA(history, order=(0,1,0))\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # Make the prediction\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X = dataset_ex_df.values\n",
    "size = int(len(X) * 0.8)\n",
    "train, test = X[0:size], X[size:len(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "    # Generate a prediction\n",
    "    yhat = arima_forecast(history)\n",
    "    predictions.append(yhat)\n",
    "    # Add the predicted value to the training set\n",
    "    obs = test[t]\n",
    "    history.append(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Actual Stock Values\n",
    "plt.figure(figsize=(12, 6), dpi=100)\n",
    "plt.plot(dataset_ex_df.iloc[size:,:].index, test, label='Real')\n",
    "plt.title('Actual Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Predicted Stock Values for Accuracy Comparison\n",
    "plt.figure(figsize=(12, 6), dpi=100)\n",
    "plt.plot(dataset_ex_df.iloc[size:,:].index, test, label='Real')\n",
    "plt.plot(dataset_ex_df.iloc[size:,:].index, predictions, color='red', label='Predicted')\n",
    "plt.title('ARIMA Predictions vs Actual Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 4) Define & Display Fourier Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Fourier Transformations\n",
    "data_FT = dataset_ex_df[['Close']]\n",
    "close_fft = np.fft.fft(np.asarray(data_FT['Close'].tolist()))\n",
    "fft_df = pd.DataFrame({'fft':close_fft})\n",
    "fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))\n",
    "fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Fourier Transformations\n",
    "plt.figure(figsize=(14, 7), dpi=100)\n",
    "plt.plot(np.asarray(data_FT['Close'].tolist()),  label='Real')\n",
    "for num_ in [3, 6, 9]:\n",
    "    fft_list_m10= np.copy(close_fft); fft_list_m10[num_:-num_]=0\n",
    "    plt.plot(np.fft.ifft(fft_list_m10), label='Fourier transform with {} components'.format(num_))\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('USD')\n",
    "plt.title('Goldman Sachs (close) stock prices & Fourier transforms')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 5) Calculate & Assess Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EMA\n",
    "def ema(close, period=20):\n",
    "    return close.ewm(span=period, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RSI\n",
    "def rsi(close, period=14):\n",
    "    delta = close.diff()\n",
    "    gain, loss = delta.copy(), delta.copy()\n",
    "    gain[gain < 0] = 0\n",
    "    loss[loss > 0] = 0\n",
    "    avg_gain = gain.rolling(period).mean()\n",
    "    avg_loss = abs(loss.rolling(period).mean())\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100.0 - (100.0 / (1.0 + rs))\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MACD\n",
    "def macd(close, fast_period=12, slow_period=26, signal_period=9):\n",
    "    fast_ema = close.ewm(span=fast_period, adjust=False).mean()\n",
    "    slow_ema = close.ewm(span=slow_period, adjust=False).mean()\n",
    "    macd_line = fast_ema - slow_ema\n",
    "    signal_line = macd_line.ewm(span=signal_period, adjust=False).mean()\n",
    "    histogram = macd_line - signal_line\n",
    "    return macd_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate OBV\n",
    "def obv(close, volume):\n",
    "    obv = np.where(close > close.shift(), volume, np.where(close < close.shift(), -volume, 0)).cumsum()\n",
    "    return obv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 6) Build Training & Test Data Using Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add technical indicators to dataset DF\n",
    "dataset_ex_df['ema_20'] = ema(gs[\"Close\"], 20)\n",
    "dataset_ex_df['ema_50'] = ema(gs[\"Close\"], 50)\n",
    "dataset_ex_df['ema_100'] = ema(gs[\"Close\"], 100)\n",
    "\n",
    "dataset_ex_df['rsi'] = rsi(gs[\"Close\"])\n",
    "dataset_ex_df['macd'] = macd(gs[\"Close\"])\n",
    "dataset_ex_df['obv'] = obv(gs[\"Close\"], gs[\"Volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arima DF using predictions\n",
    "arima_df = pd.DataFrame(history, index=dataset_ex_df.index, columns=['ARIMA'])\n",
    "\n",
    "# Set Fourier Transforms DF\n",
    "fft_df.reset_index(inplace=True)\n",
    "fft_df['index'] = pd.to_datetime(dataset_ex_df.index)\n",
    "fft_df.set_index('index', inplace=True)\n",
    "fft_df_real = pd.DataFrame(np.real(fft_df['fft']), index=fft_df.index, columns=['Fourier_real'])\n",
    "fft_df_imag = pd.DataFrame(np.imag(fft_df['fft']), index=fft_df.index, columns=['Fourier_imag'])\n",
    "\n",
    "# Technical Indicators DF\n",
    "technical_indicators_df = dataset_ex_df[['ema_20', 'ema_50', 'ema_100', 'rsi', 'macd', 'obv', 'Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DF\n",
    "merged_df = pd.concat([arima_df, fft_df_real, fft_df_imag, technical_indicators_df], axis=1)\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df\n",
    "\n",
    "# Separate in Train and Test Dfs\n",
    "train_size = int(len(merged_df) * 0.8)\n",
    "train_df, test_df = merged_df.iloc[:train_size], merged_df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_df.drop('Close', axis=1))\n",
    "test_scaled = scaler.transform(test_df.drop('Close', axis=1))\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "train_scaled_df = pd.DataFrame(train_scaled, columns=train_df.columns[:-1], index=train_df.index)\n",
    "test_scaled_df = pd.DataFrame(test_scaled, columns=test_df.columns[:-1], index=test_df.index)\n",
    "\n",
    "# Merge the scaled features with the target variable\n",
    "train_scaled_df['Close'] = train_df['Close']\n",
    "test_scaled_df['Close'] = test_df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the scaled data into Features and Label\n",
    "X_train = train_scaled_df.iloc[:, :-1].values\n",
    "y_train = train_scaled_df.iloc[:, -1].values\n",
    "X_test = test_scaled_df.iloc[:, :-1].values\n",
    "y_test = test_scaled_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 7) Training a Deep Learning Model for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with early stopping callback\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=32, verbose=1, validation_data=(X_test, y_test), callbacks=[early_stop], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate test metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "mpe = np.mean((y_test - y_pred) / y_test) * 100\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R2 Score: {r2}\")\n",
    "print(f\"Explained Variance Score: {evs}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}\")\n",
    "print(f\"Mean Percentage Error (MPE): {mpe}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final Predictions\n",
    "plt.figure(figsize=(12, 6), dpi=100)\n",
    "plt.plot(test_scaled_df.index, y_test, label='Real')\n",
    "plt.plot(test_scaled_df.index, y_pred, color='red', label='Predicted')\n",
    "plt.title('Model Predictions vs Real Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 8) Conclusion\n",
    "- ##### Now you can predict stocks you're interested in for better informed decisions in your investing!\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
